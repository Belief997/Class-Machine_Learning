{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#coding=utf-8\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\"\"\"\n",
    "plt.rcParams['figure.figsize'] = (32.0, 32.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f,encoding='latin1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    return X, Y\n",
    "def load_CIFAR10(dir):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join('datasets', dir, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join('datasets', dir, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "def distance(X_test, X_train):\n",
    "    \"\"\"\n",
    "    输入:\n",
    "    X_test -- 由numpy数组表示的测试集，大小为(d , num_test)\n",
    "    X_train -- 由numpy数组表示的训练集，大小为(d, num_train)\n",
    "    输出:\n",
    "    distances -- 测试数据与各个训练数据之间的距离,大小为(num_test, num_train)的numpy数组\n",
    "    \"\"\"\n",
    "    num_test = X_test.shape[1]\n",
    "    num_train = X_train.shape[1]\n",
    "    distances = np.zeros((num_test, num_train)) # test和train对应的数组\n",
    "    # (X_test - X_train)*(X_test - X_train) = -2X_test*X_train + X_test*X_test + X_train*X_train\n",
    "    #展开平方差公式，是不是这样就可以使用numpy的并行计算？\n",
    "    #print(X_test.shape,X_train.shape)\n",
    "    \n",
    "    dist1 = np.multiply(np.dot(X_test.T,X_train), -2)    # -2X_test*X_train, shape (num_test, num_train)\n",
    "    dist2 = np.sum(np.square(X_test.T), axis=1, keepdims=True)    # X_test*X_test, shape (num_test, 1)\n",
    "    dist3 = np.sum(np.square(X_train), axis=0,keepdims=True)    # X_train*X_train, shape(1, num_train)\n",
    "    distances = np.sqrt(dist1 + dist2 + dist3)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def predict(X_test, X_train, Y_train, k = [1]):\n",
    "    \"\"\" \n",
    "    输入:\n",
    "    X_test -- 由numpy数组表示的测试集，大小为(图片长度 * 图片高度 * 3 , 测试样本数)\n",
    "    X_train -- 由numpy数组表示的训练集，大小为(图片长度 * 图片高度 * 3 , 训练样本数)\n",
    "    Y_train -- 由numpy数组（向量）表示的训练标签，大小为 (1, 训练样本数)\n",
    "    k -- 选取与训练集最近邻的数量的list\n",
    "    输出:\n",
    "    Y_prediction -- 包含X_test中所有预测值的numpy数组（向量）\n",
    "    distances -- 由numpy数组表示的测试数据与各个训练数据之间的距离,大小为(测试样本数, 训练样本数)\n",
    "    \"\"\"\n",
    "    \n",
    "    distances = distance(X_test, X_train)\n",
    "    \n",
    "#     print(k)\n",
    "    num_test = X_test.shape[1]\n",
    "    Y_prediction = np.zeros((num_test,len(k)))\n",
    "    for i in range(num_test):\n",
    "        for j,item_k in enumerate(k):\n",
    "            dists_min_k = np.argsort(distances[i])[:item_k]     # 按照距离递增次序进行排序,选取距离最小的k个点 \n",
    "            y_labels_k = Y_train[0,dists_min_k]     # 确定前k个点的所在类别\n",
    "            Y_prediction[i][j] = np.argmax(np.bincount(y_labels_k)) # 返回前k个点中出现频率最高的类别作为测试数据的预测分类\n",
    "\n",
    "    \n",
    "    \n",
    "#     print(Y_prediction)\n",
    "    return Y_prediction\n",
    "\n",
    "def model(X_test, Y_test, X_train, Y_train, k = [1], print_correct = False):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "    X_test -- 由numpy数组表示的测试集，大小为(图片长度 * 图片高度 * 3 , 测试样本数)\n",
    "    X_train -- 由numpy数组表示的训练集，大小为(图片长度 * 图片高度 * 3 , 训练样本数)\n",
    "    Y_train -- 由numpy数组（向量）表示的训练标签，大小为 (1, 训练样本数)\n",
    "    Y_test -- 由numpy数组（向量）表示的测试标签，大小为 (1, 测试样本数)\n",
    "    k -- 选取与训练集最近邻的数量的系列数组\n",
    "    print_correct -- 设置为true时，打印正确率\n",
    "    输出：\n",
    "    d -- 包含模型信息的字典的数组\n",
    "    \"\"\"\n",
    "    Y_prediction= predict(X_test, X_train, Y_train, k)\n",
    "    num_correct = np.sum(Y_prediction == Y_test)\n",
    "    d_array=[]\n",
    "    for i,k_item in enumerate(k):\n",
    "        accuracy = np.mean(Y_prediction[:,i] == Y_test)\n",
    "        if print_correct:\n",
    "            print('Correct %d/%d: The test accuracy: %f' % (num_correct, X_test.shape[1], accuracy))\n",
    "\n",
    "        d_array.append({\"k\": k,\n",
    "             \"Y_prediction\": Y_prediction, \n",
    "    #          \"distances\" : distances,\n",
    "             \"accuracy\": accuracy})\n",
    "    #print(d_array)\n",
    "    #安装k数组里面的元素的顺序，排列成d\n",
    "    return d_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature as skft\n",
    "def Lbp(img):\n",
    "    # settings for LBP\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp = skft.local_binary_pattern(img, n_points, radius, 'default') # ‘default’, ‘ror’, ‘uniform’, ‘var’\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp, normed=True, bins=n_bins, range=(0, n_bins))\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# list\\nclasses = ['plane', 'car', 'bird', 'cat', 'dear', 'dog', 'frog', 'horse', 'ship', 'truck']\\nnum_classes = len(classes)\\nnum_each_class = 7\\n\\nfor y, cls in enumerate(classes):\\n    idxs = np.flatnonzero(y_train == y)\\n    idxs = np.random.choice(idxs, num_each_class, replace=False)\\n    for i, idx in enumerate(idxs):\\n        plt_idx = i * num_classes + (y + 1)\\n        plt.subplot(num_each_class, num_classes, plt_idx)\\n        plt.imshow(X_train[idx].astype('uint8'))\\n        plt.axis('off')\\n        if i == 0:\\n            plt.title(cls)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = '/Users/apple/cifar-10-batches-py/cifar10-data'\n",
    "\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# 训练样本，训练标签，测试集，测试标签\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# list\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'dear', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "num_each_class = 7\n",
    "\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, num_each_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + (y + 1)\n",
    "        plt.subplot(num_each_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Passing `normed=True` on non-uniform bins has always been broken, and computes neither the probability density function nor the probability mass function. The result is only correct if the bins are uniform, when density=True will produce the same result anyway. The argument will be removed in a future version of numpy.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800000\n",
      ">>size 256 \n",
      "256000\n",
      ">>size 256 \n"
     ]
    }
   ],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "size_train = 50000\n",
    "size_test = 1000\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1)).T #( ,50000) \n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1)).T    #( ,10000) \n",
    "Y_set_train = y_train[:size_train].reshape(1,-1)   # (1, )\n",
    "Y_set_test = y_test[:size_test].reshape(1,-1)   # (1, )\n",
    "\n",
    "\n",
    "X_set_train = X_train[:,:size_train]\n",
    "X_set_test = X_test[:,:size_test]\n",
    "\n",
    "del X_train, y_train\n",
    "del X_test, y_test\n",
    "\n",
    "#  转灰度图 ， 做 lbp\n",
    "X_Train_tmp = [] # list  \n",
    "X_Test_tmp = []\n",
    "test_tmp = []\n",
    "\n",
    "#print (\"size %d %d\" %(X_set_train.shape[0], X_set_train.shape[1]))#\n",
    "#print (\"size %d \" %(X_set_train.T[0].shape[0]))#\n",
    "for i in range(size_train):\n",
    "    tmp = []\n",
    "    tmp = Lbp(rgb2gray(X_set_train.T[i].reshape(32, 32,3) )).T\n",
    "    X_Train_tmp.append(tmp)\n",
    "for i in range(size_test):\n",
    "    tmp = []\n",
    "    tmp = Lbp(rgb2gray(X_set_test.T[i].reshape(32, 32,3) )).T\n",
    "    X_Test_tmp.append(tmp)\n",
    "    \n",
    "del X_set_test,X_set_train\n",
    "\n",
    "X_set_train = []\n",
    "X_set_test = []\n",
    "X_set_train = np.array(X_Train_tmp).T\n",
    "X_set_test = np.array(X_Test_tmp).T\n",
    "print (X_set_train.size)\n",
    "print (\">>size %d \" %(X_set_train.shape[0]))#\n",
    "print (X_set_test.size)\n",
    "print (\">>size %d \" %(X_set_test.shape[0]))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 50000)\n",
      "(1, 50000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:110: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "k = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]    # all k, determine the best k\n",
    "\n",
    "\n",
    "# models = {}\n",
    "# k = []\n",
    "# accuracys = []\n",
    "# # 1~10\n",
    "# for i in range(1,11):\n",
    "#     models[str(i)] = model(X_set_test, Y_set_test, X_set_train, Y_set_train, i, print_correct = False)\n",
    "#     k.append(models[str(i)][\"k\"])\n",
    "#     accuracys.append(models[str(i)][\"accuracy\"])\n",
    "# plt.plot(k, accuracys)\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('k')\n",
    "# plt.show()\n",
    "\n",
    "# del models,k,accuracys\n",
    "\n",
    "models = {}\n",
    "accuracys = []\n",
    "\n",
    "models = model(X_set_test, Y_set_test, X_set_train, Y_set_train, k, print_correct = False)\n",
    "\n",
    "for i in range(len(k)):\n",
    "    #print(models[i])\n",
    "    # k.append(models[str(i)][\"k\"])\n",
    "    accuracys.append(models[i][\"accuracy\"])\n",
    "\n",
    "plt.plot(k, accuracys)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('k')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #cross validation\n",
    "# num_folds = 5    # split the training dataset to 5 parts\n",
    "\n",
    "# print(X_set_train.shape)\n",
    "# print(Y_set_train.shape)\n",
    "# # Split up the training data into folds\n",
    "# X_train_folds = []\n",
    "# Y_train_folds = []\n",
    "# X_train_folds = np.split(X_set_train.T, num_folds)\n",
    "# Y_train_folds = np.split(Y_set_train.T, num_folds)\n",
    "\n",
    "# # A dictionary holding the accuracies for different values of k\n",
    "# k_accuracy = {}\n",
    "\n",
    "# tmp_accuracy=np.zeros((len(k),num_folds))\n",
    "\n",
    "# accuracies=[]\n",
    "\n",
    "# for i in range(num_folds):\n",
    "    \n",
    "#     X_cut_train = np.concatenate(X_train_folds[:i] + X_train_folds[i+1:]).T\n",
    "#     Y_cut_train = np.concatenate(Y_train_folds[:i] + Y_train_folds[i+1:]).T\n",
    "#     X_cross_validation = X_train_folds[i].T\n",
    "#     Y_cross_validation = Y_train_folds[i].T\n",
    "\n",
    "#     ycv_model = model(X_cross_validation,Y_cross_validation,X_cut_train,Y_cut_train,k,print_correct = False)\n",
    "#     for j,k_item in enumerate(k):   \n",
    "#         tmp_accuracy[j][i]=ycv_model[j][\"accuracy\"]\n",
    "#     #print(tmp_accuracy)\n",
    "\n",
    "# for i,k_item in enumerate(k):\n",
    "#     k_accuracy[k_item]=tmp_accuracy[i]\n",
    "\n",
    "\n",
    "\n",
    "# # Print the accuracy\n",
    "# for k_item in k:\n",
    "#     for i in range(num_folds):\n",
    "#         print('k = %d, fold = %d, accuracy: %f' % (k_item, i+1, k_accuracy[k_item][i]))\n",
    "        \n",
    "# for k_item in k:\n",
    "#     plt.scatter([k_item] * num_folds, k_accuracy[k_item]) # [k_item]数组乘以常数num_folds变成一个以为数组\n",
    "    \n",
    "# # plot the trend line with error bars that correspond to standard deviation\n",
    "# accuracies_mean = [np.mean(k_accuracy[k_item]) for k_item in k_accuracy] #计算每一个k值对应的平均值\n",
    "# accuracies_std = [np.std(k_accuracy[k_item]) for k_item in k_accuracy]   #对应每一个k值对应的标准差\n",
    "# plt.errorbar(k, accuracies_mean, yerr=accuracies_std)\n",
    "# plt.title('Cross-validation on k')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Cross-validation accuracy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
